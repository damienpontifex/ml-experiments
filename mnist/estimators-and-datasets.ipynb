{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "l = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_input_img(img):\n",
    "    # Decode bytes of image and transform to expected type and shape\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "def _tuple_to_feat_label(x, y):\n",
    "    x = _convert_input_img(x)\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return { 'image': x }, y\n",
    "  \n",
    "def make_dataset(xs, ys, batch_size=1024, shuffle=False, num_epochs=None):\n",
    "  \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((xs, ys))\n",
    "    if shuffle:\n",
    "        dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(\n",
    "            buffer_size=4096, count=num_epochs))\n",
    "    else:\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "        _tuple_to_feat_label, batch_size=batch_size))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_cnn_model_fn(features: Dict[str, tf.Tensor], labels: tf.Tensor, mode: tf.estimator.ModeKeys, params: dict):\n",
    "\n",
    "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    dropout_rate = 0\n",
    "    if is_training:\n",
    "        dropout_rate = params.get('dropout_rate', 0.4)\n",
    "\n",
    "    learning_rate = params.get('learning_rate', 1e-3)\n",
    "    decay_rate = params.get('decay_rate', 1e-6)\n",
    "    decay_steps = params.get('decay_steps', 500)\n",
    "\n",
    "    conv1 = l.Conv2D(filters=32, kernel_size=5, padding='same', activation=tf.nn.relu)(features['image'])\n",
    "    pool1 = l.MaxPooling2D(pool_size=2, strides=2, padding='same')(conv1)\n",
    "\n",
    "    conv2 = l.Conv2D(filters=64, kernel_size=5, padding='same', activation=tf.nn.relu)(pool1)\n",
    "    pool2 = l.MaxPooling2D(pool_size=2, strides=2, padding='same')(conv2)\n",
    "\n",
    "    pool2_flat = l.Flatten()(pool2)\n",
    "    dense = l.Dense(1024, activation=tf.nn.relu)(pool2_flat)\n",
    "    dropout = l.Dropout(rate=dropout_rate)(dense)\n",
    "\n",
    "    logits = l.Dense(10)(dropout)\n",
    "  \n",
    "    head = tf.contrib.estimator.multi_class_head(n_classes=10)\n",
    "  \n",
    "    decayed_learning_rate = tf.train.exponential_decay(\n",
    "        learning_rate, tf.train.get_global_step(), \n",
    "        decay_steps, decay_rate, staircase=True)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(decayed_learning_rate)\n",
    "  \n",
    "    return head.create_estimator_spec(\n",
    "        features, mode, logits, labels, optimizer=optimizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    \"\"\"Input receiver expects a batched 28x28 uint8 array of pixels\"\"\"\n",
    "\n",
    "    # Define inputs from serving receiver\n",
    "    inputs = { \n",
    "        'image': tf.placeholder(tf.uint8, shape=[None, 28, 28]) \n",
    "    }    \n",
    "    \n",
    "    # Define features passed to model_fn\n",
    "    features = {\n",
    "        'image': tf.map_fn(_convert_input_img, inputs['image'], dtype=tf.float32)\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x125406898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3110662, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 3 into /tmp/mnist/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-01-23:32:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist/model.ckpt-3\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-01-23:33:25\n",
      "INFO:tensorflow:Saving dict for global step 3: accuracy = 0.738418, average_loss = 1.5824507, global_step = 3, loss = 1.5824507\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3: /tmp/mnist/model.ckpt-3\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'image': <tf.Tensor 'Placeholder:0' shape=(?, 28, 28) dtype=uint8>}\n",
      "INFO:tensorflow:'classification' : Classification input must be a single string Tensor; got {'image': <tf.Tensor 'Placeholder:0' shape=(?, 28, 28) dtype=uint8>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist/model.ckpt-3\n",
      "WARNING:tensorflow:From /Users/ponti/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1018: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /tmp/mnist/export/mnist/temp-b'1538436806'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 1.8895667.\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    train_ds = lambda: make_dataset(x_train, y_train, shuffle=True)\n",
    "    test_ds = lambda: make_dataset(x_test, y_test)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "        mnist_cnn_model_fn, \n",
    "        model_dir=os.environ.get('MODEL_DIR', '/tmp/mnist'), \n",
    "        params={\n",
    "            'learning_rate': 1e-3,\n",
    "            'dropout_rate': 0.4,\n",
    "        })\n",
    "\n",
    "    max_steps = int(os.environ.get('MAX_STEPS', 3))\n",
    "    train_spec = tf.estimator.TrainSpec(train_ds, max_steps=max_steps)\n",
    "    \n",
    "    final_exporter = tf.estimator.FinalExporter('mnist', serving_input_receiver_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(test_ds, exporters=[final_exporter])\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['predict']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['image'] tensor_info:\n",
      "        dtype: DT_UINT8\n",
      "        shape: (-1, 28, 28)\n",
      "        name: Placeholder:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['class_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/ExpandDims:0\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/str_classes:0\n",
      "    outputs['logits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: dense_1/BiasAdd:0\n",
      "    outputs['probabilities'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: head/predictions/probabilities:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir /tmp/mnist/export/mnist/1538436806 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
