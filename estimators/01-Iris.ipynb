{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators and datasets make up TensorFlow high-level APIs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/tensorflow_programming_environment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator program structure\n",
    "\n",
    "- Import and parse the data\n",
    "- Create feature columns to describe the data\n",
    "- Select model\n",
    "- Train model\n",
    "- Evaluate model\n",
    "- Make predictions from model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/tensorflow-estimator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Premade Estimators](https://www.tensorflow.org/get_started/premade_estimators \"\" target=\"_blank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n.b. Below we will use the common root path for models as /tmp/iris. As such, tensorboard can be run as `tensorboard --logdir=/tmp/iris` and we can compare all our results next to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the [UCI Machine Learning: Iris Data Set](https://archive.ics.uci.edu/ml/datasets/iris). It has four numerical features classifying three types of iris plant. Keeping this simple means we can focus on the infrastructure around estimators without getting complexity introduced by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll grab the data and store it locally and then load it up into a pandas data frame. With other data, you'd look at missing values, distributions etc but this data is very clean and we want to focus on the estimator methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(remote_url):\n",
    "    CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "    \n",
    "    local_path = tf.keras.utils.get_file(os.path.basename(remote_url), remote_url, cache_dir=os.getcwd())\n",
    "    \n",
    "    df = pd.read_csv(local_path, header=0, names=CSV_COLUMN_NAMES)\n",
    "    \n",
    "    features, label = df, df.pop('Species')\n",
    "    \n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = get_data(TRAIN_URL)\n",
    "test_features, test_labels = get_data(TEST_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(train_labels.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators use an input function that is called to return data. It is a `callable` that returns a tuple - dictionary of features to tensors and label as tensor. The estimator module has a couple of [built in utilities](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs) for some common cases such as numpy and pandas data sources. For a much larger case of dataset capabilities, look at the [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(feature_df, label_df, shuffle=False, batch_size=128, num_epochs=None):\n",
    "    input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "        feature_df, y=label_df, batch_size=batch_size, \n",
    "        shuffle=shuffle, num_epochs=num_epochs, target_column='Species')\n",
    "    \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Feature Columns](https://www.tensorflow.org/get_started/feature_columns) act as the intermediaries between the raw data and estimators. Here we are just using numerical columns (number in, number out). \n",
    "\n",
    "Other types of columns include:\n",
    "- Bucketized: split value into different categories based on numerical range (e.g. age buckets -> [0-18, 18-25, 25-35, 35-65, 65+])\n",
    "- Categorical: one-hot encoding\n",
    "- Hashed: hash buckets for computing categories\n",
    "- Crossed: combination of features\n",
    "- Embedding: categorical features to dense (e.g. word vocabulary, post codes etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for key in train_features.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we save summary values often for our demo. Normally you would use much larger values so your compute can concentrate on compute rather than writing to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(save_summary_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "\n",
    "Start with [linear classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier \"\" target=\"_blank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_linear_classifier(model_dir):\n",
    "    classifier = tf.estimator.LinearClassifier(\n",
    "        feature_columns=feature_columns, \n",
    "        n_classes=N_CLASSES,\n",
    "        model_dir=model_dir, \n",
    "        config=run_config\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/iris/linear', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10b866470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linear_classifier = make_linear_classifier('/tmp/iris/linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris/linear/model.ckpt.\n",
      "INFO:tensorflow:loss = 140.62234, step = 1\n",
      "INFO:tensorflow:global_step/sec: 256.064\n",
      "INFO:tensorflow:loss = 39.921, step = 101 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.62\n",
      "INFO:tensorflow:loss = 27.999634, step = 201 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.149\n",
      "INFO:tensorflow:loss = 25.861763, step = 301 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 596.933\n",
      "INFO:tensorflow:loss = 23.64569, step = 401 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.322\n",
      "INFO:tensorflow:loss = 17.986433, step = 501 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.1\n",
      "INFO:tensorflow:loss = 16.413773, step = 601 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.522\n",
      "INFO:tensorflow:loss = 15.949997, step = 701 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.59\n",
      "INFO:tensorflow:loss = 18.420652, step = 801 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.793\n",
      "INFO:tensorflow:loss = 15.691225, step = 901 (0.166 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/iris/linear/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.511993.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x10b8665f8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifier.train(input_fn=make_input_fn(train_features, train_labels, shuffle=True), max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-07-02:05:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris/linear/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-07-02:05:14\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96, average_loss = 0.13049284, global_step = 1000, loss = 0.13049284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.96,\n",
       " 'average_loss': 0.13049284,\n",
       " 'loss': 0.13049284,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_classifier.evaluate(input_fn=make_input_fn(test_features, test_labels, batch_size=1), steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Model\n",
    "\n",
    "Make it a [neural network](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier \"\" target=\"_blank\"). All we need to do to move from a linear model to a deep neural network is change the class name and provide an extra parameter defining the size of the hidden layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dnn_classifier(model_dir, hidden_units=[10, 10]):\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feature_columns, \n",
    "        hidden_units=hidden_units, \n",
    "        n_classes=N_CLASSES,\n",
    "        model_dir=model_dir, \n",
    "        config=run_config\n",
    "    )\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/iris/dnn', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10a53f470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = make_dnn_classifier('/tmp/iris/dnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris/dnn/model.ckpt.\n",
      "INFO:tensorflow:loss = 446.35168, step = 1\n",
      "INFO:tensorflow:global_step/sec: 272.921\n",
      "INFO:tensorflow:loss = 18.026764, step = 101 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.557\n",
      "INFO:tensorflow:loss = 10.664019, step = 201 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.778\n",
      "INFO:tensorflow:loss = 11.549435, step = 301 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.865\n",
      "INFO:tensorflow:loss = 8.187953, step = 401 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.81\n",
      "INFO:tensorflow:loss = 7.4220843, step = 501 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.677\n",
      "INFO:tensorflow:loss = 8.770698, step = 601 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.715\n",
      "INFO:tensorflow:loss = 4.097604, step = 701 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.863\n",
      "INFO:tensorflow:loss = 12.121379, step = 801 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 596.825\n",
      "INFO:tensorflow:loss = 6.666758, step = 901 (0.168 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/iris/dnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.911545.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x10bd3f4a8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=make_input_fn(train_features, train_labels, shuffle=True), max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-07-02:05:36\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris/dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-07-02:05:36\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93, average_loss = 0.068787344, global_step = 1000, loss = 0.068787344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.93,\n",
       " 'average_loss': 0.068787344,\n",
       " 'loss': 0.068787344,\n",
       " 'global_step': 1000}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(input_fn=make_input_fn(test_features, test_labels, batch_size=1), steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris/dnn/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "predict_df = pd.DataFrame.from_dict(predict_x)\n",
    "predictions = classifier.predict(input_fn=make_input_fn(predict_df, label_df=None, shuffle=False, batch_size=1, num_epochs=1))\n",
    "\n",
    "predictions = list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logits': array([ 16.399452 ,  10.220468 , -11.1659565], dtype=float32),\n",
       "  'probabilities': array([9.9793172e-01, 2.0682446e-03, 1.0656042e-12], dtype=float32),\n",
       "  'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object)},\n",
       " {'logits': array([-2.015658  ,  6.1454844 , -0.20347175], dtype=float32),\n",
       "  'probabilities': array([2.8495639e-04, 9.9797004e-01, 1.7450220e-03], dtype=float32),\n",
       "  'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object)},\n",
       " {'logits': array([-8.667519 ,  1.99388  ,  6.1452847], dtype=float32),\n",
       "  'probabilities': array([3.63159643e-07, 1.54983075e-02, 9.84501302e-01], dtype=float32),\n",
       "  'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object)}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated train and evaluate\n",
    "\n",
    "[Train and evaluate](https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \"\" target=\"_blank\") is a utility function to provide consistent behaviour for local and distributed configurations. Currently just supports between-graph replication (graph per device)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/iris/train_and_evaluate', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10b663208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris/train_and_evaluate/model.ckpt.\n",
      "INFO:tensorflow:loss = 360.9911, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/iris/train_and_evaluate/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 20.460873.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-07-02:06:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris/train_and_evaluate/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-07-02:06:05\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.97, average_loss = 0.18972889, global_step = 100, loss = 0.18972889\n"
     ]
    }
   ],
   "source": [
    "estimator = make_dnn_classifier('/tmp/iris/train_and_evaluate')\n",
    "\n",
    "train_input_fn = make_input_fn(train_features, train_labels, shuffle=True, num_epochs=None)\n",
    "train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=100)\n",
    "\n",
    "test_input_fn = make_input_fn(test_features, test_labels, batch_size=1, num_epochs=None)\n",
    "test_spec = tf.estimator.EvalSpec(test_input_fn)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, test_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_spec = {\n",
    "    'SepalLength': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "    'SepalWidth': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "    'PetalLength': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "    'PetalWidth': tf.FixedLenFeature([], dtype=tf.float32)\n",
    "}\n",
    "serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "\n",
    "estimator.export_savedmodel('iris-exports', serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: data input pipeline and performance\n",
    "\n",
    "There is a lot of guidance around optimising the performance of your input pipeline. This was the reason `tf.data` was made and there is a complete guide at [Input Pipeline Performance Guide](https://www.tensorflow.org/versions/master/performance/datasets_performance). \n",
    "\n",
    "Considering the popular use of CSV datasets, recently a contrib function has been added to combine all of this guidance into a single method call. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrib_dataset = tf.contrib.data.make_csv_dataset(train_path, batch_size=128, column_names=CSV_COLUMN_NAMES, label_name='Species', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
