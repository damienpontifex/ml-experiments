{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkRhQvVTLkLP"
   },
   "source": [
    "# Adult Census Data Set\n",
    "\n",
    "Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset was donated to the UCI ML Repository in 1996. \n",
    "\n",
    "It is a classification task to predict if an individual wil earn an annual salary of >50K or <=50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dmvSAjImLkLS"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1408,
     "status": "ok",
     "timestamp": 1533425484542,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "6nYy6oRQLunj",
    "outputId": "79cf743e-7f8d-4b30-98ef-da6d78d9a236"
   },
   "outputs": [],
   "source": [
    "print(f'Running TensorFlow version {tf.__version__} with Python {sys.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3m00E-5LkLc"
   },
   "source": [
    "## Read the U.S. Census Data\n",
    "\n",
    "We'll be using the U.S. Census Income Dataset from 1994 and 1995 from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/adult)\n",
    "\n",
    "The problem is to predict one of two labels from the data and is commonly known as a binary classification problem. These two labels are whether each individual (row of data) has an annual income of over 50K or less than 50K.\n",
    "\n",
    "Getting data is always the first problem in machine learning. In this case we're going to download a comma separated value (CSV) file. This is basically an Excel datasheet if you've ever double clicked a file like this on your computer. It is a very common format to distribute data and has one example per row with each feature or column separated by a comma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dU5UCalXWGUZ"
   },
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Dx0AQaYfLkLg"
   },
   "outputs": [],
   "source": [
    "def retrieve_data(cache_subdirectory: str='/tmp/datasets/census') -> Tuple[str, str]:\n",
    "  \"\"\"Download the census dataset to local directory\n",
    "  \n",
    "  Args:\n",
    "    cache_subdirectory: Local directory to cache downloads\n",
    "  \n",
    "  Returns:\n",
    "    Tuple of local paths of (train, test)\n",
    "  \"\"\"\n",
    "\n",
    "  remote_files = [\n",
    "      'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', \n",
    "      'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "  ]\n",
    "\n",
    "  for file in remote_files:\n",
    "      local_fname = os.path.basename(file)\n",
    "\n",
    "      tf.keras.utils.get_file(local_fname, origin=file, cache_subdir=cache_subdirectory)\n",
    "\n",
    "      yield os.path.join(cache_subdirectory, local_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iHSQR0IyLkLk"
   },
   "outputs": [],
   "source": [
    "# Set up the full path of the csv files on disk\n",
    "train_local_file, test_local_file = retrieve_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qa2yDYPwWIvl"
   },
   "source": [
    "### Inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nia7GVGBLkLm"
   },
   "source": [
    "The [dataset page](https://archive.ics.uci.edu/ml/datasets/adult) lists attribute information about the dataset which is copied into the table below.\n",
    "\n",
    "| Column | Feature Description |\n",
    "| -------|---------------------|\n",
    "| age | continuous. |\n",
    "| workclass | Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. |\n",
    "| fnlwgt | continuous (the # people census takers believe that observation represents) |\n",
    "| education | Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. |\n",
    "| education-num | continuous (education feature in numerical form) |\n",
    "| marital-status | Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. |\n",
    "| occupation | Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. |\n",
    "| relationship | Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. |\n",
    "| race | White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. |\n",
    "| sex | Female, Male. |\n",
    "| capital-gain | continuous. |\n",
    "| capital-loss | continuous. |\n",
    "| hours-per-week | continuous. |\n",
    "| native-country | United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands. |\n",
    "\n",
    "The csv files don't have a header to label the columns so we list them out here for use in the pandas dataframe in the variable `CSV_COLUMNS`. We are also defining the column we want to predict as the `LABEL_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PoAoch4SLkLn"
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    'age', 'workclass', 'fnl', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "    'hours-per-week', 'native-country', 'income-bracket'\n",
    "]\n",
    "\n",
    "LABEL_KEY = 'income-bracket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSfzTEYmjxTV"
   },
   "source": [
    "Notebooks allow us to call `bash` functions inline by use of an exclamation mark at the start of the call. Before we start loading the data, we are going to use the bash `head` command to read and display the first few lines of our dataset file. This can be useful to get a bit of an understanding of how the dataset is formatted so we can read it in appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5808,
     "status": "ok",
     "timestamp": 1533425504672,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "5pN5nvq8O-nk",
    "outputId": "71c245a6-1895-4985-b95f-14aecda4a568"
   },
   "outputs": [],
   "source": [
    "!head -n 3 {train_local_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2938,
     "status": "ok",
     "timestamp": 1533425507698,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "TDt8tTUWP9fb",
    "outputId": "b88c70c7-2b69-41c7-a6b8-8390f5f78d07"
   },
   "outputs": [],
   "source": [
    "!head -n 3 {test_local_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K36B7_W3kItN"
   },
   "source": [
    "Viewing the dataset above, we can notice a few things:\n",
    "* Fields are separated by a command and space i.e. ', '\n",
    "* The test file has a description on the first line that isn't part of the data\n",
    "* The labels in the test file have a period whereas the labels in the train file do not\n",
    "\n",
    "We will have to use these few bits of information to just do a few transforms when loading the data so we have a clean and consistent dataset.\n",
    "\n",
    "We would normally have to consider how we deal with rows that have missing values. To keep things simple, in this case, we are just going to drop any rows that aren't complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03v4ThLZWMZn"
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysulXtSQLkLp"
   },
   "source": [
    "Load up the training data into a dataframe using our separator and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2NOW5oxWLkLq"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_local_file, index_col=None, sep=', ', \n",
    "                       header=None, engine='python', names=CSV_COLUMNS)\n",
    "\n",
    "# Drop rows with missing values\n",
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNoOovlNLkLs"
   },
   "source": [
    "Load up the test data into a dataframe using our separator, column names and drop the period from the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EDyoKgc-LkLt"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_local_file, index_col=None, sep=', ', \n",
    "                      header=1, engine='python', names=CSV_COLUMNS)\n",
    "\n",
    "# Test dataset has periods on the end of the labels we'll drop off to match the train set\n",
    "test_df['income-bracket'] = test_df['income-bracket'].apply(lambda val: val[:-1])\n",
    "\n",
    "# Drop rows with missing values\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkrTsJLSLkLv"
   },
   "source": [
    "Similar to our use of the bash `head` command previously, we can now visualise the first few rows of our dataframe by using the `head()` function provided by pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1533425513516,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "Hku5l3-pLkLv",
    "outputId": "f410626a-a971-4a52-83f5-dc8d1e355355"
   },
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAj4Ba1OlWtc"
   },
   "source": [
    "Visualising the distribution of the dataset can also be useful to give some intuition about the problem. It can also provide some insights into what features may be useful as predictors.\n",
    "\n",
    "You can also see the large distribution that values can take within a feature. In machine learning this can pose problems as the relative weighting of the number 1 to 1,000 to 1,000,000 can be troublesome for the optimiser to learn appropriate weights. To handle this, we can normalise a feature by scaling it by subtracting the average and dividing by the standard deviation of that feature.\n",
    "\n",
    "To keep things simple here we will ignore values that don't have a simple distribution or are extremely skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3993,
     "status": "ok",
     "timestamp": 1533425517606,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "y8xp8jLB408_",
    "outputId": "fa90d3db-65cd-43cf-818c-a925b30a3e23"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,20))\n",
    "ax = fig.gca()\n",
    "train_df.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1827,
     "status": "ok",
     "timestamp": 1533425519465,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "3tQWi11qLkL1",
    "outputId": "208a31b7-ec57-4e68-c504-10ab7da324b9"
   },
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxN75XD4WQDC"
   },
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HA4TANDhLkL5"
   },
   "source": [
    "We have both numeric and categorical data but the model only knows how to deal with numbers.\n",
    "\n",
    "Categorical features is a feature that can be one of a limited number of possible values. As an example, in this dataset, the 'sex' column is either Male or Female. To use this type of feature in our model, we will have to transform it in some way so it becomes a number which we'll show below.\n",
    "\n",
    "The other types of features are natively numeric and their magnitude has some meaning. We will define the list of numeric and categorical feature columns by their names so we can appropriately transform each before being used in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "I5ykLO_YQQac"
   },
   "outputs": [],
   "source": [
    "NUMERIC_FEATURE_KEYS = [\n",
    "    'age', 'hours-per-week'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURE_KEYS = [\n",
    "    'workclass', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "    'race', 'sex', 'native-country'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also handy to know the unique list of values a column can have (especially the labels). Here we'll just grab the unique list of labels which we expect to be `['<=50K', '>50K']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_VOCAB = list(train_df['income-bracket'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RNZL2DtbLkL6"
   },
   "source": [
    "### TensorFlow Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erVwc8IBLkL7"
   },
   "source": [
    "TensorFlow wants to have a function it can call each time it wants more data. Here we'll use built in utilities that create functions from our pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "a4QKvIdiLkL7"
   },
   "outputs": [],
   "source": [
    "train_x = train_df.drop(LABEL_KEY, axis=1)\n",
    "train_y = train_df[LABEL_KEY]\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(x=train_x, y=train_y, shuffle=True, num_epochs=None, batch_size=1024)\n",
    "\n",
    "test_x = test_df.drop(LABEL_KEY, axis=1)\n",
    "test_y = test_df[LABEL_KEY]\n",
    "test_input_fn = tf.estimator.inputs.pandas_input_fn(x=test_x, y=test_y, shuffle=False, num_epochs=None, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEPtRX0VLkL9"
   },
   "source": [
    "As we mentioned above, numeric and categorical columns need to be fed differently into our model.\n",
    "\n",
    "Firstly we'll just map our numeric data columns to TensorFlow feature columns directly (n.b. there is many more interesting ways that these columns could be used: look at [normalisation](https://en.wikipedia.org/wiki/Feature_scaling), [bucketized columns](https://www.tensorflow.org/api_docs/python/tf/feature_column/bucketized_column) and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_D5u0pCtLkL-"
   },
   "outputs": [],
   "source": [
    "real_valued_columns = [tf.feature_column.numeric_column(key, shape=()) \n",
    "                       for key in NUMERIC_FEATURE_KEYS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at the categorical columns: the simplest method is to 'One-Hot-Encode' the data. \n",
    "\n",
    "The method has a list of zeroes for each feature with the same length as the number of categories. A one is set for the column indicating the matched category. An example looking at countries:\n",
    "\n",
    "If our country list = 'Australia', 'England', 'Canada', 'New Zealand'\n",
    "\n",
    "If our row of data has 'Australia' then our one-hot encoded values are `[1, 0, 0, 0]` \n",
    "\n",
    "'Canada' -> `[0, 0, 1, 0]`\n",
    "\n",
    "'England' -> `[0, 1, 0, 0]`\n",
    "\n",
    "'New Zealand' -> `[0, 0, 0, 1]`\n",
    "\n",
    "TensorFlow provides a utility function for this and the code below will create all the transforms from our categorical features to one-hot columns for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_D5u0pCtLkL-"
   },
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    tf.feature_column.indicator_column(\n",
    "        tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key, train_df[key].unique()))\n",
    "    for key in CATEGORICAL_FEATURE_KEYS\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally just create a list of inputs that has both our numeric and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_D5u0pCtLkL-"
   },
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = real_valued_columns + categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_qqxNLzLkL_"
   },
   "source": [
    "## Linear Model\n",
    "\n",
    "Although deep neural networks are generating a lot of amazing results, they are computationally expensive compared to a linear model. We start with the simplest model we can to:\n",
    "1. Quickly see if our code works ;) \n",
    "2. Get a baseline for accuracy that a simple model can achieve\n",
    "3. Use this simple model if it provides sufficient accuracy for our desires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fYlQJvoCkQp9"
   },
   "outputs": [],
   "source": [
    "linear_model_dir = tempfile.mkdtemp(prefix='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2001,
     "status": "ok",
     "timestamp": 1533425545368,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "X_YNJsniLkMA",
    "outputId": "fbd1eb4f-10e5-4ca9-ef9a-38cfe6be1d71"
   },
   "outputs": [],
   "source": [
    "linear_classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=INPUT_COLUMNS, \n",
    "    label_vocabulary=LABEL_VOCAB, \n",
    "    model_dir=linear_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7404,
     "status": "ok",
     "timestamp": 1533425552937,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "o47L6slDTU83",
    "outputId": "4c79f656-f580-41a7-fa3a-883decd3b371"
   },
   "outputs": [],
   "source": [
    "linear_classifier.train(train_input_fn, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5730,
     "status": "ok",
     "timestamp": 1533425558706,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "nYHDYo-RTXhr",
    "outputId": "e87300d0-cc69-48c4-e26d-862d6cbd1bf7"
   },
   "outputs": [],
   "source": [
    "linear_results = linear_classifier.evaluate(test_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1919,
     "status": "ok",
     "timestamp": 1533425560667,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "MavyKq52TemI",
    "outputId": "7899d35a-119d-4764-af9e-2e9910d2feb5"
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(linear_results.items()):\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=2000)\n",
    "eval_spec = tf.estimator.EvalSpec(test_input_fn)\n",
    "tf.estimator.train_and_evaluate(linear_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmZ1HIKsqd7i"
   },
   "source": [
    "## Deep Neural Networks\n",
    "\n",
    "We're running a neural network with 4 hidden layers and using the TensorFlow DNNClassifier estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YxxZZ-vNW_AP"
   },
   "outputs": [],
   "source": [
    "dnn_model_dir = tempfile.mkdtemp(prefix='dnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1533427131198,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "PRfXCpj5TpgU",
    "outputId": "556a7464-f1ea-4e60-939c-bbc125cb8951"
   },
   "outputs": [],
   "source": [
    "dnn_classifier = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[100, 70, 50, 25], \n",
    "    feature_columns=INPUT_COLUMNS, \n",
    "    model_dir=dnn_model_dir, \n",
    "    n_classes=len(LABEL_VOCAB), \n",
    "    label_vocabulary=LABEL_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5696,
     "status": "ok",
     "timestamp": 1533427216383,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "578pNH2aXISE",
    "outputId": "dcade827-02b7-41ca-af53-b4b772799e8c"
   },
   "outputs": [],
   "source": [
    "dnn_classifier.train(train_input_fn, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7702,
     "status": "ok",
     "timestamp": 1533427224116,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "jAp3yC73XIKl",
    "outputId": "d88433db-cabc-4e5b-e24b-0698575b2c22"
   },
   "outputs": [],
   "source": [
    "dnn_results = dnn_classifier.evaluate(test_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1533427225404,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "RaOmBukgXNvo",
    "outputId": "ccb9a1e7-0954-4fa7-9e51-1267518cd4d2"
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(dnn_results.items()):\n",
    "  print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5xgGa_egYXQ1"
   },
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=2000)\n",
    "eval_spec = tf.estimator.EvalSpec(test_input_fn)\n",
    "tf.estimator.train_and_evaluate(dnn_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZVaF3r3VktT"
   },
   "source": [
    "## Hosting\n",
    "\n",
    "We can export our trained model and host it as a REST API so we can utilise it as a web service. To do this, you will need docker on your local machine to host the container.\n",
    "\n",
    "In prediction (inference) mode, there are a lot of pieces we can drop out of our model. \n",
    "* We don't need to update variables so variables become constants\n",
    "* We aren't updating weights so all of the gradient operations are removed\n",
    "* There's no loss function so that is removed\n",
    "\n",
    "These all help to reduce the size of the model on disk and improve its performance when its only purpose is to do inference.\n",
    "\n",
    "TensorFlow estimators will take care of all of this for us when we call `export_savedmodel`. Below we are also defining the signature of what we expect our incoming data to be. This is so a server hosting the model can appropriately receive data and format so our model can predict with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1474,
     "status": "ok",
     "timestamp": 1533425585133,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "sLRqrYmOTqp7",
    "outputId": "510a1ecf-3101-47d0-fad6-5b085414c217"
   },
   "outputs": [],
   "source": [
    "feature_spec = tf.feature_column.make_parse_example_spec(INPUT_COLUMNS)\n",
    "\n",
    "serving_input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "\n",
    "linear_export_dir = linear_classifier.export_savedmodel('exports', serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1533425605040,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "whNbG3CkZo1A",
    "outputId": "bc0698ca-8005-4189-d847-2c6666bcf0a3"
   },
   "outputs": [],
   "source": [
    "if os.path.isdir('linear_census_model'):\n",
    "  shutil.rmtree('linear_census_model')\n",
    "\n",
    "shutil.copytree('exports', 'linear_census_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2483,
     "status": "ok",
     "timestamp": 1533425608246,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "mwDTF4vLTqlN",
    "outputId": "40b49db4-4190-4b4c-86ae-6ca0a70859a3"
   },
   "outputs": [],
   "source": [
    "!zip -r linear_census_model.zip linear_census_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MGDs9R4TTqUx"
   },
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jzMiG0VGYX13"
   },
   "outputs": [],
   "source": [
    "files.download('linear_census_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZsRPGPo0Q4Rk"
   },
   "source": [
    "To run a server locally we can use the TensorFlow Serving docker image.\n",
    "\n",
    "```bash\n",
    "cd ~/Downloads\n",
    "unzip linear_census_model.zip\n",
    "docker pull tensorflow/serving:latest\n",
    "docker run -d \\\n",
    "  -p 8501:8501 \\\n",
    "  -e MODEL_NAME=linear_census_model \\\n",
    "  -v $(pwd)/linear_census_model:/models/linear_census_model \\\n",
    "  --name serving_linear \\\n",
    "  tensorflow/serving:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J6ugZSCr4NMw"
   },
   "source": [
    "List out unique values for each categorical feature. We need this as requests to our service will have to match the values from training data to be able to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1533417343832,
     "user": {
      "displayName": "Damien Pontifex",
      "photoUrl": "//lh6.googleusercontent.com/-vzx8iRgnijo/AAAAAAAAAAI/AAAAAAAACYo/wxqtg8T5C5Y/s50-c-k-no/photo.jpg",
      "userId": "108154422920170673093"
     },
     "user_tz": -480
    },
    "id": "c-xaOCXyqd_e",
    "outputId": "c1fdfaa3-fefe-4cef-e1bb-04a7a3c2dd3b"
   },
   "outputs": [],
   "source": [
    "for feature in CATEGORICAL_FEATURE_KEYS:\n",
    "  print(feature)\n",
    "  print(list(train_df[feature].unique()))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgMgKXbmszP_"
   },
   "source": [
    "http://localhost:8501//v1/models/linear_census_model:classify\n",
    "\n",
    "Request body\n",
    "```json\n",
    "{\n",
    "  \"examples\": [\n",
    "    {\n",
    "      \"age\": 31.0,\n",
    "      \"hours-per-week\": 40.0,\n",
    "      \"workclass\": \"Private\",\n",
    "      \"education\": \"Bachelors\",\n",
    "      \"marital-status\": \"Never-married\",\n",
    "      \"occupation\": \"Prof-specialty\",\n",
    "      \"relationship\": \"Unmarried\",\n",
    "      \"race\": \"White\",\n",
    "      \"sex\": \"Male\",\n",
    "      \"native-country\": \"Australia\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Response\n",
    "```json\n",
    "{\n",
    "    \"results\": [\n",
    "        [\n",
    "            [\n",
    "                \"<=50K\",\n",
    "                0.818707\n",
    "            ],\n",
    "            [\n",
    "                \">50K\",\n",
    "                0.181293\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hZVaF3r3VktT"
   ],
   "default_view": {},
   "name": "Binary50kIncomePrediction.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
